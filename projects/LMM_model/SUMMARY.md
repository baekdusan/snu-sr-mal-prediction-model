# MAL Prediction Model - Executive Summary

**í”„ë¡œì íŠ¸ ìš”ì•½ (1í˜ì´ì§€ ë²„ì „)**

---

## ğŸ¯ ëª©ì 

ì‚¬ìš©ì ì¿¼ë¦¬ì— ëŒ€í•œ **Maximum Acceptable Latency (MAL)**ë¥¼ ë‹¤ì–‘í•œ percentile ìˆ˜ì¤€ì—ì„œ ì˜ˆì¸¡

**í•µì‹¬ ì§ˆë¬¸**: "ì´ ì‚¬ìš©ìê°€ ì´ ì¿¼ë¦¬ì—ì„œ 90% í™•ë¥ ë¡œ ìˆ˜ìš©í•  ìˆ˜ ìˆëŠ” ìµœëŒ€ ì§€ì—°ì‹œê°„ì€?"

---

## ğŸ“Š ë°ì´í„°

**ì…ë ¥ ë°ì´í„°:**
- `all_data.xlsx`: 80ëª… Ã— 256 queries = 2,560 observations
- `augmented_data.csv`: 256 queries Ã— 51 features

**ìµœì¢… ë°ì´í„°ì…‹:**
- 2,560 rows Ã— 55 columns
- `participant_id`, `query_id`, `MAL`, `log_MAL`, 51 features

---

## ğŸ”¬ ë°©ë²•ë¡ 

### ì„ í˜• í˜¼í•© ëª¨ë¸ (Linear Mixed Model)

```
log(MAL_ij) = Î²â‚€ + Î²'X_i + u_participant(j) + Îµ_ij
```

**êµ¬ì„±:**
- **Fixed Effects (Î²'X)**: ì¿¼ë¦¬ featuresì˜ íš¨ê³¼ (51ê°œ)
- **Random Effect (u_j)**: ì‚¬ëŒë³„ "ê¸°ë‹¤ë¦¼ ì„±í–¥"
- **Residual (Îµ)**: ê°œë³„ ì˜¤ì°¨

**ì „ì²˜ë¦¬:**
- MAL ë¡œê·¸ ë³€í™˜ (Skewness: 2.99 â†’ -0.12)
- Multicollinearity ì œê±° (51 â†’ 49 features)

---

## ğŸ† ì„±ëŠ¥

### ì˜ˆì¸¡ ì •í™•ë„

| Metric | Log Scale | Original Scale |
|--------|-----------|----------------|
| **RÂ²** | 0.75 | 0.65 |
| **RMSE** | 0.42 | 12.03ì´ˆ |
| **MAE** | 0.32 | 6.72ì´ˆ |
| **Correlation** | 0.87 | 0.82 |

**í‰ê·  MAL = 21.9ì´ˆ** â†’ ì˜¤ì°¨ìœ¨ ì•½ 30%

### ë¶„ì‚° ë¶„í•´ (í•µì‹¬ ë°œê²¬!)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Participant variance:  72.0% â­ â”‚  â† ê°œì¸ì°¨ê°€ ì••ë„ì !
â”‚ Residual variance:     28.0%    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ICC = 0.72** â†’ ê°™ì€ ì‚¬ëŒì˜ MALì€ 72%ê°€ ê°œì¸ ì„±í–¥ìœ¼ë¡œ ì„¤ëª…ë¨

---

## ğŸ’¡ ì£¼ìš” ë°œê²¬

### 1. ê°œì¸ì°¨ >> ì¿¼ë¦¬ ì°¨ì´

**Model 1 (Participant RE)**: RÂ² = 0.75 âœ…
**Model 2 (Query RE)**: RÂ² = 0.11 âŒ

â†’ **ê²°ë¡ **: MALì€ ê°œì¸ íŠ¹ì„±ì´ë©°, ê°œì¸í™” í•„ìˆ˜!

### 2. ìœ ì˜ë¯¸í•œ Features (13ê°œ)

**MAL ì¦ê°€ ìš”ì¸:**
- ì–¸ì–´ ë³µì¡ë„ â†‘ (+0.92) â†’ 2.5ë°° ì¦ê°€
- êµ¬ì¡°í™” ì¶œë ¥ í•„ìš” (+0.48)

**MAL ê°ì†Œ ìš”ì¸:**
- ë‚ ì”¨ ê´€ë ¨ ì¿¼ë¦¬ (-0.44)
- ìº˜ë¦°ë”/ì¼ì • (-0.24)
- íŠ¹ì • í•­ëª© ì°¾ê¸° (-0.19)

### 3. Personalized vs Population

| ì‹œë‚˜ë¦¬ì˜¤ | MAE | ì‚¬ìš© ì‹œì  |
|---------|-----|----------|
| **Population-level** | 12.0ì´ˆ | ì‹ ê·œ ì‚¬ìš©ì (cold-start) |
| **Personalized** | 6.7ì´ˆ | 5~10ê°œ ì¿¼ë¦¬ í›„ |

**ê°œì„ ìœ¨: 67%** ğŸ‰

---

## ğŸš€ ì˜ˆì¸¡ API

### ì‚¬ìš©ë²•

```python
# ëª¨ë¸ ë¡œë“œ
import pickle
with open('models/mal_predictor.pkl', 'rb') as f:
    predictor = pickle.load(f)

# 90% percentile ì˜ˆì¸¡
result = predictor.predict_mal_percentile(
    features=extracted_features,
    percentile=90,
    participant_id='P013'  # or None for cold-start
)

print(f"90% MAL: {result['mal_seconds']:.1f}ì´ˆ")
```

### ì¶œë ¥

```python
{
    'mal_seconds': 52.95,           # ì˜ˆì¸¡ê°’
    'scenario': 'personalized',     # or 'population-level'
    'percentile': 90,
    'confidence_interval_95': (17.67, 61.86)
}
```

---

## ğŸ“ˆ ì‹¤ì „ í™œìš©

### 1. ì ì‘í˜• UI/UX
```python
if predicted_mal_90 > 30:
    show_progress_bar()  # ì˜¤ë˜ ê±¸ë¦¼
else:
    show_spinner()  # ë¹ ë¦„
```

### 2. ê°œì¸ë³„ ìµœì í™”
```python
if user_patience < -0.5:
    optimize_for_speed()  # ì°¸ì„ì„± ë‚®ìŒ
else:
    optimize_for_quality()  # ì°¸ì„ì„± ë†’ìŒ
```

### 3. ì¿¼ë¦¬ ì¶”ì²œ
```python
if complexity > 0.8:
    suggest("ë” ê°„ë‹¨íˆ ì§ˆë¬¸í•´ë³´ì„¸ìš”")
```

---

## âš ï¸ í•œê³„

1. **Within-participant RÂ² = 0.21** (ë‚®ìŒ)
   - ê°™ì€ ì‚¬ëŒë„ ì¿¼ë¦¬ë§ˆë‹¤ ë³€ë™ í¼
   - â†’ Percentileë¡œ uncertainty ëª…ì‹œ

2. **Feature Extraction ë¯¸êµ¬í˜„**
   - í˜„ì¬: features ì§ì ‘ ì œê³µ í•„ìš”
   - í–¥í›„: ì¿¼ë¦¬ í…ìŠ¤íŠ¸ â†’ ìë™ ì¶”ì¶œ

3. **Cold-start ì„±ëŠ¥**
   - ì‹ ê·œ ì‚¬ìš©ì: MAE 12ì´ˆ (moderate)
   - 5~10ê°œ í›„: MAE 6.7ì´ˆ (good)

---

## ğŸ”® ê°œì„  ë°©í–¥

### ë‹¨ê¸° (1~2ê°œì›”)
- [ ] Feature extraction íŒŒì´í”„ë¼ì¸
- [ ] Online learning (ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸)
- [ ] A/B testing

### ì¤‘ê¸° (3~6ê°œì›”)
- [ ] Crossed random effects (participant + query)
- [ ] Contextual features (ì‹œê°„, ë””ë°”ì´ìŠ¤)
- [ ] Bayesian approach (brms)

### ì¥ê¸° (6ê°œì›”~)
- [ ] Deep learning (BERT embeddings)
- [ ] Multi-level model (session hierarchy)
- [ ] Causal inference

---

## ğŸ“‚ ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
LMM_model/
â”œâ”€â”€ data/              # ì›ë³¸ ë° ì²˜ë¦¬ ë°ì´í„°
â”œâ”€â”€ models/            # í•™ìŠµëœ ëª¨ë¸ (.pkl)
â”œâ”€â”€ scripts/           # Python ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ outputs/           # ê²°ê³¼ ë° ì‹œê°í™”
â”œâ”€â”€ README.md          # ì „ì²´ ë¬¸ì„œ (ìƒì„¸)
â”œâ”€â”€ QUICKSTART.md      # ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ
â””â”€â”€ SUMMARY.md         # ì´ íŒŒì¼ (ìš”ì•½)
```

---

## ğŸ“Š ëª¨ë¸ ìŠ¤í™ ì¹´ë“œ

| í•­ëª© | ê°’ |
|------|---|
| **Training Size** | 2,560 obs (256 queries Ã— 80 participants) |
| **Features** | 49 (preprocessed) |
| **Model** | LMM with Participant Random Effect |
| **RÂ²** | 0.75 (log), 0.65 (original) |
| **RMSE** | 12.03ì´ˆ |
| **MAE** | 6.72ì´ˆ |
| **ICC** | 0.72 |
| **Significant Features** | 13/49 (p < 0.05) |

---

## âœ… TL;DR

**3ì¤„ ìš”ì•½:**
1. **ê°œì¸ì°¨ê°€ 72%** - MALì€ ê°œì¸ íŠ¹ì„±ì´ë©° ê°œì¸í™” í•„ìˆ˜
2. **RÂ² = 0.75** - ìš°ìˆ˜í•œ ì˜ˆì¸¡ë ¥ (MAE 6.7ì´ˆ)
3. **Percentile ì˜ˆì¸¡** - Cold-start ì§€ì›, ì‹¤ì „ ë°°í¬ ê°€ëŠ¥

**í•µì‹¬ ê°€ì¹˜:**
- âœ… ê°œì¸í™”ëœ MAL ì˜ˆì¸¡ (67% ì„±ëŠ¥ í–¥ìƒ)
- âœ… Uncertainty quantification (50%, 90%, 95% percentile)
- âœ… Cold-start ì†”ë£¨ì…˜ (population baseline)
- âœ… í•´ì„ ê°€ëŠ¥í•œ features (ì¿¼ë¦¬ ìµœì í™” ê°€ì´ë“œ)

**ì‚¬ìš© ì˜ˆ:**
```python
predictor.predict_mal_percentile(features, percentile=90, participant_id='P013')
â†’ {'mal_seconds': 52.9, 'scenario': 'personalized'}
```

---

**End of Executive Summary**

ğŸ“– ì „ì²´ ë¬¸ì„œ: [README.md](README.md)
âš¡ ë¹ ë¥¸ ì‹œì‘: [QUICKSTART.md](QUICKSTART.md)
