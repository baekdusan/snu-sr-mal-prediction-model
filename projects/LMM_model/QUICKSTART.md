# MAL Predictor - Quick Start Guide

**ì¿¼ë¦¬ í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ MAL ì˜ˆì¸¡ - OpenAI GPT-4o-mini ì‚¬ìš©!** âš¡

---

## ğŸ‰ ìë™ Feature ì¶”ì¶œ

ì¿¼ë¦¬ í…ìŠ¤íŠ¸ë§Œ ì…ë ¥í•˜ë©´ LLM(GPT-4o-mini)ì´ ìë™ìœ¼ë¡œ 51ê°œ featuresë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤!

```python
query = "ì§€ë‚œì£¼ì— ì°ì€ ê³¨í”„ ìŠ¤ìœ™ ì˜ìƒ ë³´ì—¬ì¤˜"
features = extractor.extract_features(query)  # âœ¨ LLMì´ ìë™ ì¶”ì¶œ!
```

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 0. ì‚¬ì „ ìš”êµ¬ì‚¬í•­

```bash
# OpenAI API í‚¤ ì„¤ì •
export OPENAI_API_KEY=your_api_key_here

# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install openai
```

### 1. End-to-End ì˜ˆì¸¡ (ê°€ì¥ ê°„ë‹¨!)

```python
import sys
sys.path.append('scripts')

from feature_extractor import QueryFeatureExtractor
from mal_percentile_predictor import MALPercentilePredictor
import pickle

# ëª¨ë¸ ë¡œë“œ
with open('models/mal_predictor.pkl', 'rb') as f:
    predictor = pickle.load(f)

# Feature extractor ì´ˆê¸°í™”
extractor = QueryFeatureExtractor()

# ì¿¼ë¦¬ í…ìŠ¤íŠ¸ë¡œ ë°”ë¡œ ì˜ˆì¸¡!
query = "ì˜¤ëŠ˜ ë‚ ì”¨ì— ì í•©í•œ íŒ¨ì…˜ ìŠ¤íƒ€ì¼ ì¶”ì²œí•´ì¤˜"

# Step 1: Features ìë™ ì¶”ì¶œ
features = extractor.extract_features(query)

# Step 2: MAL ì˜ˆì¸¡
result = predictor.predict_mal_percentile(
    features=features,
    percentile=90,
    participant_id='P013'  # or None for cold-start
)

print(f"90% ìˆ˜ìš© MAL: {result['mal_seconds']:.1f}ì´ˆ")
```

### 2. ì „ì²´ ë°ëª¨ ì‹¤í–‰

```bash
cd LMM_model/scripts
export OPENAI_API_KEY=your_key
python end_to_end_demo.py
```

---

## ğŸ“– ìƒì„¸ ì‚¬ìš©ë²•

### Feature Extractor ì‚¬ìš©

```python
from feature_extractor import QueryFeatureExtractor

extractor = QueryFeatureExtractor()

# ë‹¨ì¼ ì¿¼ë¦¬
features = extractor.extract_features("ì´ë²ˆ ë‹¬ì— ì´ ì–¼ë§ˆë‚˜ ì¼ì§€?")

print(f"Extracted {len(features)} features:")
print(f"  Task type: {features['QL_task_type']}")
print(f"  Goal: {features['QL_goal_type']}")
print(f"  Financial domain: {features['QL_financial_domain']}")
# ... 51 features total

# ë°°ì¹˜ ì²˜ë¦¬
queries = [
    "ì§€ë‚œì£¼ì— ì°ì€ ì‚¬ì§„ ë³´ì—¬ì¤˜",
    "ì˜¤ëŠ˜ ë‚ ì”¨ ì¶”ì²œ",
    "ì†Œì—°ì´ê°€ ë§í–ˆë˜ ì˜í™” ì œëª©"
]

results = extractor.extract_batch(queries)
for r in results:
    if r['success']:
        print(f"âœ“ {r['query']}: {len(r['features'])} features")
    else:
        print(f"âœ— {r['query']}: {r['error']}")
```

### í†µí•© ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸

```python
def predict_mal_from_text(query_text, user_id=None, percentile=90):
    """
    ì¿¼ë¦¬ í…ìŠ¤íŠ¸ë¡œë¶€í„° MAL ì˜ˆì¸¡

    Args:
        query_text: ì‚¬ìš©ì ì¿¼ë¦¬ (í•œêµ­ì–´)
        user_id: ì‚¬ìš©ì ID (optional)
        percentile: ì›í•˜ëŠ” percentile (default: 90)

    Returns:
        float: ì˜ˆì¸¡ëœ MAL (ì´ˆ)
    """
    # Feature ì¶”ì¶œ
    features = extractor.extract_features(query_text)

    # MAL ì˜ˆì¸¡
    result = predictor.predict_mal_percentile(
        features=features,
        percentile=percentile,
        participant_id=user_id
    )

    return result['mal_seconds']


# ì‚¬ìš© ì˜ˆì‹œ
mal_90 = predict_mal_from_text(
    "í˜„ì¬ ìœ„ì¹˜ì—ì„œ ê±¸ì–´ì„œ ê°ˆ ìˆ˜ ìˆëŠ” ë§›ì§‘ ì¶”ì²œí•´ì¤˜",
    user_id='P013',
    percentile=90
)

if mal_90 > 30:
    show_progress_bar()
else:
    show_spinner()
```

---

## ğŸ’¡ ì‹¤ì „ í™œìš© ì˜ˆì‹œ

### 1. ì ì‘í˜• UI/UX

```python
# ì¿¼ë¦¬ ë°›ê¸°
query = user_input()

# Feature ì¶”ì¶œ
features = extractor.extract_features(query)

# 90th percentile ì˜ˆì¸¡
mal_90 = predictor.predict_mal_percentile(
    features=features,
    percentile=90,
    participant_id=current_user_id
)['mal_seconds']

# UI ê²°ì •
if mal_90 > 30:
    show_progress_bar(f"ì²˜ë¦¬ ì¤‘... (~{mal_90:.0f}ì´ˆ)")
elif mal_90 > 10:
    show_spinner("ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
else:
    show_instant_response()
```

### 2. ì¿¼ë¦¬ ë³µì¡ë„ ì•ˆë‚´

```python
features = extractor.extract_features(query)

if features['QL_language_complexity_proxy'] > 0.8:
    warn_user("ë³µì¡í•œ ì§ˆë¬¸ì…ë‹ˆë‹¤. ê°„ë‹¨íˆ ë‹¤ì‹œ ë¬¼ì–´ë³´ì‹œê² ì–´ìš”?")

if features['QL_requires_cross_modal']:
    inform_user("ì—¬ëŸ¬ ë°ì´í„°ë¥¼ ì¢…í•© ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.")
```

### 3. ë‹¤ì¤‘ Percentile ì œê³µ

```python
features = extractor.extract_features(query)

results = predictor.predict_multiple_percentiles(
    features=features,
    percentiles=[50, 90, 95],
    participant_id=user_id
)

show_to_user(f"""
ì˜ˆìƒ ëŒ€ê¸° ì‹œê°„:
  â€¢ ë³´í†µ: {results['p50']['mal_seconds']:.0f}ì´ˆ
  â€¢ ì•ˆì „í•˜ê²Œ: {results['p90']['mal_seconds']:.0f}ì´ˆ
  â€¢ ìµœëŒ€: {results['p95']['mal_seconds']:.0f}ì´ˆ
""")
```

---

## ğŸ” Feature ì¶”ì¶œ ìƒì„¸

### LLM ê¸°ë°˜ ìë™ ì¶”ì¶œ

Feature extractorëŠ” OpenAI GPT-4o-minië¥¼ ì‚¬ìš©í•˜ì—¬ `feature_specification.md`ì— ì •ì˜ëœ 51ê°œ featuresë¥¼ ìë™ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.

**ì¥ì :**
- âœ… ìˆ˜ë™ ì…ë ¥ ë¶ˆí•„ìš”
- âœ… ì¼ê´€ëœ ì¶”ì¶œ í’ˆì§ˆ
- âœ… ë¹ ë¥¸ ì‘ë‹µ (~1-2ì´ˆ)
- âœ… ì €ë ´í•œ ë¹„ìš© (~$0.0001/query)

**ì „ì²´ Feature ëª©ë¡:**
```python
# outputs/required_features.csv ì°¸ì¡°
import pandas as pd
features_list = pd.read_csv('outputs/required_features.csv')
print(features_list)
```

---

## âš ï¸ ì£¼ì˜ì‚¬í•­

### 1. API í‚¤ í•„ìˆ˜

```bash
# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
export OPENAI_API_KEY=sk-...

# ë˜ëŠ” Pythonì—ì„œ
import os
os.environ['OPENAI_API_KEY'] = 'sk-...'
```

### 2. API ë¹„ìš©

- **GPT-4o-mini**: ~$0.0001/query (ë§¤ìš° ì €ë ´!)
- **Anthropic Claude**: ~$0.003/query (30ë°° ë¹„ìŒˆ)
- ë°°ì¹˜ ì²˜ë¦¬ ì‹œì—ë„ ë¶€ë‹´ ì—†ìŒ

### 3. ì„±ëŠ¥

- Feature ì¶”ì¶œ: ~1-2ì´ˆ/ì¿¼ë¦¬ (GPT-4o-mini)
- MAL ì˜ˆì¸¡: ~0.01ì´ˆ
- **ë³‘ëª©: Feature ì¶”ì¶œ** â†’ ìºì‹± ê¶Œì¥

---

## ğŸ†˜ ë¬¸ì œ í•´ê²°

### Q1: "OPENAI_API_KEY not found" ì—ëŸ¬
**A**: API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ì„¸ìš”
```bash
export OPENAI_API_KEY=your_key_here
```

### Q2: Feature ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ
**A**: ìˆ˜ë™ìœ¼ë¡œ features ì œê³µ ê°€ëŠ¥
```python
# Fallback: ìˆ˜ë™ features
manual_features = {
    'QL_task_type': 'retrieve_item',
    'QL_goal_type': 'remember/recall',
    # ... provide manually
}

result = predictor.predict_mal_percentile(
    features=manual_features,
    percentile=90
)
```

### Q3: ìºì‹± êµ¬í˜„
**A**: ê°™ì€ ì¿¼ë¦¬ ì¬ì‚¬ìš©
```python
# ìºì‹± ì˜ˆì‹œ
feature_cache = {}

def get_features_cached(query):
    if query not in feature_cache:
        feature_cache[query] = extractor.extract_features(query)
    return feature_cache[query]
```

---

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ

### GPT-4o-mini vs Claude

| Metric | GPT-4o-mini | Claude Sonnet |
|--------|-------------|---------------|
| **ë¹„ìš©/query** | ~$0.0001 âœ… | ~$0.003 |
| **ì†ë„** | ~1-2ì´ˆ âœ… | ~2-3ì´ˆ |
| **í’ˆì§ˆ** | ë§¤ìš° ìš°ìˆ˜ âœ… | ë§¤ìš° ìš°ìˆ˜ |
| **ì•ˆì •ì„±** | ë†’ìŒ âœ… | ë†’ìŒ |

**ê²°ë¡ **: GPT-4o-miniê°€ ë¹„ìš© íš¨ìœ¨ì ì´ê³  ë¹ ë¦„!

---

## ğŸ“š ë” ì•Œì•„ë³´ê¸°

- ì „ì²´ ë¬¸ì„œ: [README.md](README.md)
- Feature ì •ì˜: `../feature_specification.md`
- ì „ì²´ ë°ëª¨: `python scripts/end_to_end_demo.py`

---

## ğŸ¯ TL;DR

```python
# 3ì¤„ë¡œ ëë‚´ëŠ” MAL ì˜ˆì¸¡
from feature_extractor import QueryFeatureExtractor
from mal_percentile_predictor import MALPercentilePredictor

extractor = QueryFeatureExtractor()  # OPENAI_API_KEY í•„ìš”
predictor = MALPercentilePredictor()

# ì¿¼ë¦¬ â†’ ì˜ˆì¸¡
query = "ì˜¤ëŠ˜ ë‚ ì”¨ì— ë§ëŠ” ì˜· ì¶”ì²œí•´ì¤˜"
features = extractor.extract_features(query)  # GPT-4o-mini ìë™ ì¶”ì¶œ
result = predictor.predict_mal_percentile(features, percentile=90)
print(f"90% MAL: {result['mal_seconds']:.1f}ì´ˆ")
```

**ë!** ğŸ‰

---

**Made with â¤ï¸ using OpenAI GPT-4o-mini + Linear Mixed Models**
